{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2e93b03",
   "metadata": {},
   "source": [
    "# Introduction to Gaussian Naive Bayes\n",
    "\n",
    "Gaussian Naive Bayes is a probabilistic classification algorithm based on Bayes' Theorem, assuming that features follow a normal (Gaussian) distribution and are conditionally independent given the class label.\n",
    "\n",
    "## Bayes' Theorem\n",
    "\n",
    "$$\n",
    "P(y \\mid X) = \\frac{P(X \\mid y) \\cdot P(y)}{P(X)}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $P(y \\mid X)$ is the posterior probability of class $y$ given features $X$.\n",
    "- $P(X \\mid y)$ is the likelihood of features $X$ given class $y$.\n",
    "- $P(y)$ is the prior probability of class $y$.\n",
    "- $P(X)$ is the probability of features $X$.\n",
    "\n",
    "## Gaussian Likelihood\n",
    "\n",
    "For each feature $x_i$, the likelihood under the Gaussian assumption is:\n",
    "\n",
    "$$\n",
    "P(x_i \\mid y) = \\frac{1}{\\sqrt{2\\pi\\sigma_{y,i}^2}} \\exp\\left(-\\frac{(x_i - \\mu_{y,i})^2}{2\\sigma_{y,i}^2}\\right)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\mu_{y,i}$ is the mean of feature $i$ for class $y$.\n",
    "- $\\sigma_{y,i}^2$ is the variance of feature $i$ for class $y$.\n",
    "\n",
    "## Classification Rule\n",
    "\n",
    "The predicted class $\\hat{y}$ for a sample $X$ is:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\arg\\max_{y} \\; P(y) \\prod_{i=1}^{n} P(x_i \\mid y)\n",
    "$$\n",
    "\n",
    "Gaussian Naive Bayes is simple, efficient, and often effective for high-dimensional datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b85d03",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
